---
title: "BCB420: Assignment 1"
subtitle: "Data Cleaning and Processing of Bulk RNA-Sequencing Data of Neutrophils Affected by Triple-Negative Breast Cancer (TNBC)"
author: "Katarina Vucic"
date: "02/11/2025"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: flatly
    highlight: tango
    fig_caption: true
    df_print: paged 
    code_folding: hide
bibliography: A1_references.bib
nocite: '@*'
link-citations: true
---

# Introduction

While cancer is one of the most studied diseases in the world, the immune landscape of cancer patients is largely uncharacterized. Previous research has demonstrated that tumours can affect the immune system's response, leading to variations in disease progression and treatment outcomes [@blomberg2018; @mcallister2014].

Neutrophils are a type of white blood cell that play a critical role in the body's immune response [@nci2019]. They respond to conditions in the body by releasing enzymes to destroy microorganisms [@nci2019]. Neutrophils also help to activate other immune cells, making them vital to the immune system [@nci2019]. 

Triple-Negative Breast Cancer (TNBC) is a particularly aggressive breast cancer subtype with a high mortality rate [@acs2023]. To investigate immune response in TNBC patients, Bakker et. al performed a bulk RNA-seq experiment designed to identify the differences in the expression of genes in the neutrophils of TNBC patients and healthy donors [@bakker2025]. 

In this analysis, we continue the work of Bakker et. al by examining their bulk RNA-sequencing results to investigate the expression patterns of genes in TNBC patients.


---

# Dataset Import

Bakker et. al conducted a bulk RNA-sequencing experiment involving neutrophils from seven patients with metastatic TNBC (mTNBC). Of the mTNBC pateints, one sample was chemotherapy-na√Øve, one was chemo-free for more than 1 year, and the remaining 5 received recent chemotherapy [@bakker2025]. They also sequenced the neutrophils from seven healthy donors (HDs) for a control group [@bakker2025]. 

We begin by importing relevant packages for our analysis. We will be using GEOquery [@geoquery] to retrieve the GEO data; edgeR [@edgeR] for normalization; ggplot2 [@ggplot2] for plotting; and reshape2 [@reshape2], tidyr [@tidyr], and dplyr [@dplyr] for data manipulation.
```{r, message=FALSE, warning=FALSE, error=FALSE, results='hide'}
library(GEOquery)
library(edgeR)
library(ggplot2)
library(reshape2)
library(tidyr)
library(dplyr)
```

The results for this experiment are stored in the Gene Expression Omnibus (GEO) with accession number `GSE264108` [@barrett2012]. We will begin by retrieving the meta-data for this experiemnt and examine the summary of the experiment we are accessing.
```{r, message=FALSE, warning=FALSE}
data_set_geoid <- "GSE264108"
# retrieve data from GEO
gse <- getGEO(data_set_geoid, GSEMatrix = FALSE)
gse@header$summary
```

There are two bulk RNA-sequencing datasets associated with this paper, raw counts and normalized counts. We will be using the raw counts, since we will be doing the cleaning and normalization from scratch. If the file is downloaded already, the following code will simply import it from your system.

```{r, message=FALSE, warning=FALSE}
# retrieve the dataset filenames
sfilenames <- getGEOSuppFiles(data_set_geoid, fetch_files = FALSE)

# set dataset filename and working directory for retrieval
data_filename <- sfilenames$fname[1]
#data_filename <- "GSE264108_readcounts.txt.gz"
download_dir <- file.path(getwd())

# check if the file exists before downloading
if(!file.exists(file.path(download_dir,data_set_geoid, data_filename))){
  sfiles = getGEOSuppFiles(data_set_geoid,
                           baseDir = download_dir, 
                           fetch_files = TRUE)
}

# read in tab-separated data 
tnbc_data <- read.table(
  file.path(download_dir,data_set_geoid,data_filename),
  header=TRUE,
  sep="\t",
  check.names=TRUE)
dim(tnbc_data)
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

This dataset contains `9048` genes. In the paper, the authors state that they removed genes with zero expression across all samples, so not all genes included in the bulk RNA-sequencing are included in this dataset [@bakker2025].  

---

# Dataset Cleaning

In order to better understand the data we are working with, we will begin by cleaning up the table as it is now. The raw format of the data can be seen below.

```{r, message=FALSE, warning=FALSE}
head(tnbc_data)
```

---

## Table Cleaning

There are 14 samples, as well as meta-data for each gene in the data set. To improve our analysis, we split this data into 2 tables, one for the sample meta-data and another for the read counts.

First, we pull out the sample meta-data so that we can map each sample to a more human-readable descriptor.

```{r, message=FALSE, warning=FALSE}
# retrieve the list of samples
list_of_samples <- gse@gsms

# pull out relevant metadata for each sample
sample_type <- do.call(rbind, 
                        lapply(list_of_samples, FUN=function(x){
                          c(x@header$title,
                            x@header$characteristics_ch1)}))

# convert to a data frame
sample_df <- as.data.frame(sample_type, stringsAsFactors = FALSE)
colnames(sample_df) <- c("sample", "sampleCondition", "cellType", "diseaseState")
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

Now, we perform some simple string manipulations to clean up the dataframe, and we are left with a summary of our samples.

```{r, message=FALSE, warning=FALSE}
# remove matching text to reduce redundancy
sample_df[,'sample'] <- gsub(sample_df[,'sample'],
                                pattern = "Neutrophils ",
                                replacement = "")
sample_df[,'sampleCondition'] <- gsub(sample_df[,'sampleCondition'],
                                             pattern = "tissue: ",
                                             replacement = "")
sample_df[,'cellType'] <- gsub(sample_df[,'cellType'],
                                       pattern = "cell type: ",
                                       replacement = "")
sample_df[,'diseaseState'] <- gsub(sample_df[,'diseaseState'],
                                    pattern = "disease state: ",
                                    replacement = "")

sample_df
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

There are 14 samples present in this experiment, 7 from mTNBC patients and 7 from healthy donors. All samples had the same sequencing protocol, with FACS sorting done on neutrophils in the blood for each sample.

Next, we map our samples back to the read count dataframe so that we can use the accessions more easily. 

```{r, message=FALSE, warning=FALSE}
# set the colomn names of our data to the sample names
colnames(tnbc_data)[2:15] <- sample_df$sample
```

---

## Removing Low Read Counts

Now that our dataset is in a suitable format for reading, we will clean the actual read counts in the dataset. First, we begin by analyzing the distribution of the data.

```{r, message=FALSE, warning=FALSE}
data.frame(do.call(cbind, lapply(tnbc_data[, 2:15], summary)))
```

*This code was inspired by the response by A5C1D2H2I1M1N2O1R2T1 to this Stack Overflow question [@chiam2015].*

The 1st quantile is 0 for all samples, and the mean values are very low, implying we have quite a few genes with low read counts.

Low read counts are not always a bad thing, if there are low read counts for a gene in one condition but higher read counts in another it could indicate differential experession! However, low read counts in many samples could introduce noise when we want to calculate our differential expression [@isserlin2025]. Since there are 7 of each disease state, we will remove any gene that does not have expression in at least 7 of the samples. Choosing 7 allows us to keep the genes that possibly have low read counts in all of the samples in one condition and none of the other [@isserlin2025].

```{r, message=FALSE, warning=FALSE}
rownames(tnbc_data) <- tnbc_data$ensembl_gene_id
min_num_samples <- 7
data_matrix <- as.matrix(tnbc_data[ , 2:15])
keep = rowSums(edgeR::cpm(data_matrix) >1) > min_num_samples
filtered_tnbc_data = data.frame(data_matrix[keep,])
dim(filtered_tnbc_data)
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

This leaves us with 3693 genes that have enough expression to be analyzed downstream. To confirm we have removed most of our low read counts, we can reasses the distribution of the read coutns across samples.


```{r, message=FALSE, warning=FALSE}
data.frame(do.call(cbind, lapply(filtered_tnbc_data, summary)))
```

*This code was inspired by the response by A5C1D2H2I1M1N2O1R2T1 to this Stack Overflow question [@chiam2015].*

The 1st quantile is no longer 0 and the median has increased significantly, implying our low-count removal was successful.

---

## Identifier Mapping

Until now, we have been using the ENSEMBL gene ids to map our data. While ENSEMBL is quite common for gene identifiers, most tools use the HUGO Gene Nomenclature Committee (HGNC) name for each gene instead, since it is the standardized nomenclature for human genes [@seal2022]. Our dataset already stores the HGNC symbols for each gene in the `external_gene_id` column. 

We could have dealt with these genes earlier, however, there are some duplicates in the HGNC symbols so we must deal with them first before setting the gene symbols. We let filtering take care of some of these lowly-expressed genes first, and now we can analyze the remaining duplicated genes.


```{r, message=FALSE, warning=FALSE}
# identify duplicate gene identifiers in the tnbc_data
dup_genes <- tnbc_data[duplicated(tnbc_data$external_gene_id),]

# retrieve counts for duplicated data in the filtered dataframe
dup_ensembls <- tnbc_data$ensembl_gene_id[tnbc_data$external_gene_id %in% dup_genes$external_gene_id]

# retrieve duplicate ids in filtered_tnbc_data
filtered_dup_genes <- rownames(filtered_tnbc_data)[rownames(filtered_tnbc_data) %in% dup_ensembls]

filtered_dup_tnbc_data <- filtered_tnbc_data[rownames(filtered_tnbc_data) %in% filtered_dup_genes, ]
tnbc_data[filtered_dup_genes, c("ensembl_gene_id", "external_gene_id")]

```

We have duplicate values for `Y_RNA`, `WDFY4`, `Metazoa_SRP`, `EMG1`, and `LINC01481`. Because of our read count filtering, `WDFY4`, `EMG1`, and `LINC01481` are no longer duplicates so we do not have to worry about them anymore. We can analyze the expression values of `Y_RNA` and `Metazoa_SRP`, to see if there is a lot of variance between the genes.

```{r, message=FALSE, warning=FALSE}
# reshape the data from wide to long format for plotting
plot_filtered_dup_tnbc_data <- filtered_dup_tnbc_data
plot_filtered_dup_tnbc_data$gene <- rownames(filtered_dup_tnbc_data)
plot_filtered_dup_tnbc_data <- plot_filtered_dup_tnbc_data %>%
  pivot_longer(cols = -gene, names_to = "sample", values_to = "expression")
plot_filtered_dup_tnbc_data$hgnc <- tnbc_data$external_gene_id[match(plot_filtered_dup_tnbc_data$gene, tnbc_data$ensembl_gene_id)]
plot_filtered_dup_tnbc_data <- plot_filtered_dup_tnbc_data[plot_filtered_dup_tnbc_data$hgnc %in% c("Y_RNA", "Metazoa_SRP"), ]

# plot the expression data per sample for Y_RNA
ggplot(plot_filtered_dup_tnbc_data, aes(x = sample, y = expression, color = hgnc, group = gene)) +
  # draw line 
  geom_line(size = 1) + 
  # draw points
  geom_point(size = 2) + 
  theme_minimal() +
  labs(title = "Duplicate Gene Counts Across Samples",
       caption = "The distribution of raw counts across samples in genes annotated with HGNC symbol Y_RNA and Metazoa_SRP.",
       x = "Sample",
       y = "Counts") +
  # angle text so sample is readable
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The `Y_RNA` and `Metazoa_SRP` genes generally follow a similar trend across samples within their HGNC name, so we will take the mean of the expression value of the genes sharing the same HGNC name for the read counts for `Y_RNA` and `Metazoa_SRP.

```{r, message=FALSE, warning=FALSE}
# create a column for HGNC symbols
filtered_tnbc_data$hgnc <- tnbc_data$external_gene_id[match(rownames(filtered_tnbc_data), rownames(tnbc_data))]

# group by hgnc symbols and remove duplicates
filtered_tnbc_data <- filtered_tnbc_data %>% 
  dplyr::group_by(hgnc) %>% 
  dplyr::summarise(dplyr::across(where(is.numeric), \(x) mean(x, na.rm = TRUE)))

# remove hgnc symbol column in clean version
clean_tnbc_data <- data.frame(filtered_tnbc_data[ , !(colnames(filtered_tnbc_data) %in% c("hgnc"))])

# set rownames to hgnc symbols
rownames(clean_tnbc_data) <- filtered_tnbc_data$hgnc
```

*This code was inspired by the response by Greg to this Stack Overflow question [@elrey2022].*

Now our data is clean and ready for normalization!

---

## Replicate Data 

To confirm variability across genes, we will look at if there are any genes that have the same read counts. It is highly unlikely that genes will have the same read count since there is an infinite number of values for each read count value and there are 14 samples. Thus, replicate rows could imply some issue with the sequencing that may need to be removed.

```{r}
dup_read_counts <- clean_tnbc_data[duplicated(clean_tnbc_data),]

dim(dup_read_counts)
```

The duplicate read count table is empty, meaning every gene has unique counts across samples.

We will do the same to check if any of the samples are replicated.

```{r}
dup_samples <- clean_tnbc_data[ , duplicated(as.list(clean_tnbc_data))]

dim(dup_samples)
```

The duplicate sample table is empty, meaning every sample has unique counts across genes

---

## Quality Checks

To ensure that the data is clean before we begin analyzing, we will assess if there are any non-numeric or null values.

```{r, message=FALSE, warning=FALSE}
# ensure the dataset contains only numeric values
data_numeric_check <- !all(sapply(clean_tnbc_data, is.numeric))

# count missing values (NAs) in the dataset
na_count <- sum(is.na(clean_tnbc_data))

data.frame(
  check = c("Dataset contains non-numeric data", 
            "Dataset contains missing values (NAs)"),
  result = c(as.logical(data_numeric_check), as.logical(na_count)),
  stringsAsFactors = FALSE
)
```

Our data has no non-numeric data or NAs. Here is a snapshot of our data now.

```{r, message=FALSE, warning=FALSE}
clean_tnbc_data[1:5, ]
```

Our data is now clean and ready for normalization!


---

# Data Normalization

In RNA-Seq analysis, the raw counts of gene expression can be affected by various factors that are not related to the biological differences we aim to study. These factors include technical variation from experimental procedures, sample preparation, and sequencing condition. **Normalization** is a process that aims to standardize these technical differences in order to reduce variability so that the observed differences in gene expression reflect *biological* variability instead of *technical* variability. For this analysis, we will be using the `edgeR` package [@edgeR].

Let's take a look at the distribution of our data before we begin any normalization.

```{r, message=FALSE, warning=FALSE}
plot_count_distribution <- function(count_data, title = "RNASeq Samples") {
  data2plot <- log2(count_data)
  boxplot(data2plot, xlab = "Samples", ylab = "log2 TPM",
    las = 2, cex = 0.5, cex.lab = 0.5,
    cex.axis = 0.5, main = "RNASeq Samples")
  #draw the median on each box plot
  abline(h = median(apply(data2plot, 2, median)),
    col = "green", lwd = 0.6, lty = "dashed")
  mtext("Boxplot of TNBC RNASeq data for each sample", side = 1, line = 4, cex = 0.75)
  
  counts_density <- apply(log2(count_data), 2, density)
    #calculate the limits across all the samples
    xlim <- 0; ylim <- 0
    for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x));
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
    cols <- rainbow(length(counts_density))
    ltys <- rep(1, length(counts_density))
    #plot the first density plot to initialize the plot
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n",
      ylab="Smoothing density of log2-CPM",
      main=paste(title, "- Density Plot"), cex.lab = 0.85)
    #plot each line
    for (i in 1:length(counts_density))
      lines(counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(data2plot),
      col=cols, lty=ltys, cex=0.75,
      border ="blue", text.col = "green4",
      merge = TRUE, bg = "gray90")
    mtext("Desnity plot of TNBC RNASeq data for each sample.", side = 1, line = 4, cex = 0.75)
}

plot_count_distribution(clean_tnbc_data, title = "Clean TNBC Data")
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

---

## Trimmed Mean of M-values (TMM) Normalization

A common method for normalizing out technical variation is **Trimmed Mean of M-values (TMM)**, which is a sample-based normalization method based on the hypothesis that most genes are not differentially expressed [CITATION]. This method normalizes data by selecting a reference sample, calculating fold changes relative to it, and trimming out differentially expressed genes. The trimmed mean of fold changes and the total count of the sample are then used to scale the read counts [@evans2017].

```{r, message=FALSE, warning=FALSE}
tnbc_dge_list <- edgeR::DGEList(counts=clean_tnbc_data, group=sample_df$diseaseState)
tnbc_dge_list <- calcNormFactors(tnbc_dge_list)
normalized_tnbc_data <- data.frame(cpm(tnbc_dge_list))
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

We can now re-inspect our data distribution to see that the data is more normalized. Normalized data should have more aligned means across samples, with the distribution more centered and resembling a normal distribution.

```{r, message=FALSE, warning=FALSE}
plot_count_distribution(normalized_tnbc_data, title = "Filtered TNBC Data")
```

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*

---

## Outlier Analysis

Now that our data is normalized, we can take a look at the number and range of outliers in our dataset. To do this we will use **Interquartile Range (IQR)**, to find the ranges of the lowest 25% and top 75% of our data [@soetewey2020].

```{r}
# calculate the interquartile range for each sample in the normalized data
clean_quantile_1 <- apply(clean_tnbc_data, 2, quantile, 0.25)
clean_quantile_3 <- apply(clean_tnbc_data, 2, quantile, 0.75)
clean_iqr <- clean_quantile_3 - clean_quantile_1

# calculate the lower and upper bounds for each sample in the normalized data
clean_lower_bound <- clean_quantile_1 - (1.5 * clean_iqr)
clean_upper_bound <- clean_quantile_3 + (1.5 * clean_iqr)

# calculate the interquartile range for each sample in the normalized data
norm_quantile_1 <- apply(normalized_tnbc_data, 2, quantile, 0.25)
norm_quantile_3 <- apply(normalized_tnbc_data, 2, quantile, 0.75)
norm_iqr <- norm_quantile_3 - norm_quantile_1

# calculate the lower and upper bounds for each sample in the normalized data
norm_lower_bound <- norm_quantile_1 - (1.5 * norm_iqr)
norm_upper_bound <- norm_quantile_3 + (1.5 * norm_iqr)

data.frame(rbind(clean_lower_bound, clean_upper_bound, norm_lower_bound, norm_upper_bound))
```
*This code was inspired by this Outliers detection in R tutorial [@soetewey2020].*

We see that after normalization, the upper and lower bounds of the outliers became tighter, and the interquartile range is very similar across samples.

```{r, message=FALSE, warning=FALSE}
# check if data is within the outlier bounds for each sample
clean_within_range <- clean_tnbc_data >= clean_lower_bound & clean_tnbc_data <= clean_upper_bound

# sum the count of genes per sample
clean_outlier_percent <- (dim(clean_tnbc_data)[1] - colSums(clean_within_range)) / dim(clean_tnbc_data)[1]

# check if data is within the outlier bounds for each sample
norm_within_range <- normalized_tnbc_data >= norm_lower_bound & normalized_tnbc_data <= norm_upper_bound

# sum the count of genes per sample
norm_outlier_percent <- (dim(normalized_tnbc_data)[1] - colSums(norm_within_range)) / dim(normalized_tnbc_data)[1]

data.frame(rbind(clean_outlier_percent, norm_outlier_percent))
```

Roughly 14% of the data in each sample is an outlier. Let's take a look at the size of our dataset again.

```{r, message=FALSE, warning=FALSE}
dim(normalized_tnbc_data)
```

The final coverage of our dataset is `3690` genes across `14` samples.

---

## Data Separation By Sample

A good way to visualize the relationship between samples is through a **Multidimensional Scaling (MDS)** plot. This plot helps us assess the similarities between samples based on their expression profiles [@hout2013]. By applying MDS, we can check how well the samples are grouped by their biological characteristics, such as disease state [@hout2013].

In the MDS plot, samples that are similar in gene expression should cluster together, while samples that are very different should be placed farther apart.

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*
```{r, message=FALSE, warning=FALSE}
limma::plotMDS(tnbc_dge_list, labels=NULL, pch = 1,
               col = c("darkgreen","blue")[factor(sample_df$diseaseState)])

legend("topright", 
       legend=levels(factor(sample_df$diseaseState)),
  pch=c(1), col= c("darkgreen","blue"),title="Class",
  bty = 'n', cex = 0.75)

mtext("MDS plot of TNBC RNASeq data coloured by disease state.", side = 1, line = 4, cex = 0.75)
```

Here we see that there is a nice separation of data between disease states! This means there may be a good amount of differentially expressed genes across our disease states.


---

# Analysis 

Now, let's take a look at the underlying distribution of the data again to see if there may be any issues when we perform differential expression.

---

## Dataset Variance 

The **dispersion** of the dataset represents how much the variance deviates from the mean across the samples. In RNA-Seq data, we expect the variance to follow a negative binomial distribution, with the variance increasing with the mean expression level [@anders2013].

By calculating dispersion, we can see the consistency of gene expression across samples. A large dispersion suggests that there is large variability in gene expression, which could either be biologically meaningful or technical variation.

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*
```{r, message=FALSE, warning=FALSE}
model_design <- model.matrix(~sample_df$diseaseState)
tnbc_dispersion <- estimateDisp(tnbc_dge_list, model_design)
plotBCV(tnbc_dispersion,col.tagwise = "black",col.common = "red",)
mtext("Dispersion plot of TNBC RNASeq data.", side = 1, line = 4, cex = 0.75)
```

We will now examine the overall distribution of variance across all genes. In particular, we want to examine whether the variance increases with the mean expression levels following the negative binomial distribution [@anders2013]. If the variance is unevenly distributed or significantly deviating from the negative binomial distribution, it may cause issues later when performing differential gene analysis.

*This code was modified from the lectures for BCB420: Computational Systems Biology [@isserlin2025].*
```{r, message=FALSE, warning=FALSE}
plotMeanVar(tnbc_dispersion, show.raw.vars = TRUE, NBline=TRUE)
mtext("Mean-Variance plot of TNBC RNASeq data with the Negative Binomial line in Blue.", side = 1, line = 4, cex = 0.75)
```

From our analysis, we find that the dataset involves a high degree of variance, but it tends to follow the negative binomial model, which is needed for differential expression downstream with edgeR [@edgeR]. 


---

# Conclusion

In the process of cleaning and normalizing the data, we are left with `3690` genes in our bulk RNA-sequencing experiment. This dataset includes the neutrophils of 7 mTNBC patients in the test set and 7 healthy donors in the control group. All Ensembl IDs were mapped to HGNC symbols by the original authors. There were 3 duplicate Ensembl IDs for the HGNC symbol `Y_RNA`, and after analyzing their trend across samples we decided to average their counts. The quality checking showed that the data is clean with no missing or weird values. To normalize the data, we used TMM normalization to reduce technical noise. Using the the MDS plot, we see that our samples group nicely by disease state. The final coverage of our dataset is 3690 genes across 14 samples.


---

# Discussion

The following contains a guide to the discussion questions for A1. Clicking on the question links back to the section where the analysis was performed, and a brief answer is provided for easy access.

[**Why is the dataset of interest to you?**](#discussion)

This area of research is particularly meaningful to me because cancer research was the first field I wanted to enter as a child, and it is still one of the most interesting fields I have done research in. I chose this paper on Triple Negative Breast Cancer in specific because it is a very aggressive subtype with low mortality, meaning there is a lot of recent work done in the field. TNBC is also a primary focus in the lab I am working in, and although it is not my area of research I hear quite a bit about it in journal club. I wanted to choose something outside of the standard tumour sequencing areas, and I thought examining the neutrophils in the blood was an interesting direction I have not heard much about!

[**What are the control and test conditions of the dataset?**](#introduction)

This test group of this dataset are patients with mTNBC and the control group are healthy donors.

[**How many samples in each of the conditions of your dataset?**](#introduction)

This dataset includes 7 mTNBC samples and 7 healthy donor samples.

[**Were there expression values that were not unique for specific genes? How did you handle these?**](#identifier-mapping)

There were 3 duplicate Ensembl IDs for the HGNC symbol `Y_RNA` and 2 for the Ensembl ID `Metazoa_SRP`, and after analyzing their trend across samples we decided to average their counts.

[**Were there expression values that could not be mapped to current HUGO symbols?**](#identifier-mapping)

All Ensembl IDs were mapped to HGNC symbols by the original authors.

[**Were there any outliers in your dataset? How were they handled in the originating paper? How many outliers were removed?**](#outlier-analysis)

The original paper does not mention handling outliers. Since this dataset is smaller than the full human genome, it is very possible that they filtered out the outliers first. We did not remove any outliers, instead we applied TMM normalization to reduce their affect on the downstream analysis

[**How did you handle replicates?**](#replicate-data)

There were no replicate genes or samples, although I did check for them in the data.

[**What is the final coverage of your dataset?**](#conclusion)

The final coverage of our dataset is `3690` genes across `14` samples.


# References

